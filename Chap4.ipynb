{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3bcc52-e53d-443e-a99f-f802524182d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üéØ Abaque de Gy et QA/QC\n",
    "\n",
    "Les analyses de **QA/QC** sont inspir√©es de :\n",
    "\n",
    "> üìö *Rafini, S., 2015*. **Assurance et contr√¥le de la qualit√© (QA/QC) en exploration min√©rale** : synth√®se et √©valuation des usages. Rapport, Projet CONSOREM 2013-05, 44 p.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6ed420-f27f-4acd-801e-9fb5db259ceb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üéØ Abaque de Gy interactif\n",
    "\n",
    "Ce notebook permet de visualiser les lignes d'isocontours de l'√©cart-type relatif de Gy.\n",
    "\n",
    "Vous pouvez entrer vos propres param√®tres, les valider, et obtenir une proc√©dure graphique adapt√©e √† vos √©tapes.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ √âtapes :\n",
    "\n",
    "1. Entrer vos param√®tres globaux :  \n",
    "- **al** : proportion massique du lot analys√©  \n",
    "- **da**, **dg** : densit√©s apparente et r√©elle  \n",
    "- **d0** : taille du plus petit fragment (en cm)  \n",
    "- **ml** : masse totale du lot (en g)  \n",
    "- **s_vals** : liste des √©carts-types relatifs souhait√©s (ex. `[0.1, 0.2]`)\n",
    "\n",
    "2. Ajouter une ou plusieurs √©tapes avec leurs param√®tres sp√©cifiques :  \n",
    "- **me** : masse d‚Äô√©chantillon (en g)  \n",
    "- **ml** : masse totale √† l‚Äô√©tape (en g)  \n",
    "- **d** : taille max des fragments (en cm)\n",
    "\n",
    "3. Visualiser l‚Äôabaque mis √† jour avec :  \n",
    "- les lignes d‚Äôisocontours en noir pour les √©carts-types choisis  \n",
    "- les points rouges repr√©sentant chaque √©tape saisie  \n",
    "- les fl√®ches bleues indiquant la progression entre √©tapes  \n",
    "- le calcul et l‚Äôaffichage de l‚Äô√©cart-type relatif global (sr global)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Exemple de sortie :\n",
    "\n",
    "L‚Äôabaque affiche une √©chelle logarithmique en abscisse (taille des fragments, cm) et en ordonn√©e (masse de l‚Äô√©chantillon, g).  \n",
    "Les courbes noires sont les isocontours pour les √©carts-types relatifs choisis, tandis que les courbes en gris pointill√© correspondent √† au maillage logarithmique.\n",
    "\n",
    "Chaque point rouge correspond √† une √©tape saisie, avec sa valeur sr affich√©e en rouge √† c√¥t√©.  \n",
    "Les fl√®ches bleues montrent le cheminement entre √©tapes.  \n",
    "\n",
    "Enfin, le sr global (√©cart-type total combin√©) est indiqu√© en bleu en haut √† gauche.\n",
    "\n",
    "---\n",
    "\n",
    "> **Remarque** : les calculs reposent sur les param√®tres et formules sp√©cifiques √† la g√©otechnique mini√®re.  \n",
    "> Assurez-vous de bien ajuster les valeurs selon votre contexte d‚Äô√©tude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "978b3962-3356-4af0-baeb-938d4c5282e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55bf968f5f64922baafec70ae955175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Param√®tres globaux :'), HBox(children=(FloatText(value=0.014925373134328358, descr‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from ipywidgets import VBox, HBox, Button, FloatText, Output, Label, Layout\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Variables globales initiales\n",
    "params = {\n",
    "    'al': 0.010 / 0.67,\n",
    "    'da': 4.1,\n",
    "    'dg': 2.8,\n",
    "    'd0': 0.1\n",
    "}\n",
    "\n",
    "# Widgets pour les param√®tres globaux\n",
    "al_input = FloatText(description='al (conc.)', value=params['al'], step=0.01, layout=Layout(width='160px'))\n",
    "da_input = FloatText(description='da (densit√© min.)', value=params['da'], step=0.1, layout=Layout(width='160px'))\n",
    "dg_input = FloatText(description='dg (densit√© gangue)', value=params['dg'], step=0.1, layout=Layout(width='160px'))\n",
    "d0_input = FloatText(description='d0 (taille lib.)', value=params['d0'], step=0.0001, layout=Layout(width='160px'))\n",
    "\n",
    "params_widgets = HBox([al_input, da_input, dg_input, d0_input])\n",
    "\n",
    "def gy(al, da, dg, ml, d0, me=None, d=None, sr=None, f=0.5, g=0.25):\n",
    "    if d is None:\n",
    "        fl = 1.0\n",
    "    else:\n",
    "        fl = min(np.sqrt(d0 / d), 1.0)\n",
    "    ud = (1 - al) / al * ((1 - al) * da + al * dg)\n",
    "    k2 = ud * f * g\n",
    "    k = ud * f * g * fl\n",
    "    if me is None:\n",
    "        ime = sr**2 / k / d**3 + 1 / ml\n",
    "        sr = 1 / ime\n",
    "    elif d is None:\n",
    "        for _ in range(10):\n",
    "            d3 = sr**2 / k / (1 / me - 1 / ml)\n",
    "            d = d3 ** (1 / 3)\n",
    "            fl = min(np.sqrt(d0 / d), 1.0)\n",
    "            k = ud * f * g * fl\n",
    "        sr = d\n",
    "    else:\n",
    "        s2 = k * d**3 / me * (1 - me / ml)\n",
    "        sr = np.sqrt(s2)\n",
    "    return sr\n",
    "\n",
    "def plot_gy_iso_contours(ax, al, da, dg, d0, ml, s_vals=[0.1]):\n",
    "    \"\"\"\n",
    "    Trace les lignes d'isocontours de l'√©cart-type relatif de Gy sur l'axe `ax`.\n",
    "    \"\"\"\n",
    "    f, g = 0.5, 0.25\n",
    "    d = np.exp(np.linspace(-7, 3, 100))  # tailles de fragments en cm\n",
    "    flib = np.minimum(1, np.sqrt(d0 / d))\n",
    "    ud = (1 - al) / al * ((1 - al) * da + al * dg)\n",
    "    k = ud * f * g * flib * d**3\n",
    "\n",
    "    ymin, ymax = 1, 1e4\n",
    "    for s in s_vals:\n",
    "        me = 1 / (s**2 / k + 1 / ml)\n",
    "        ax.loglog(d, me, 'k', linewidth=1.5)\n",
    "        # Ajout texte (facultatif)\n",
    "        i = np.argmin(np.abs(me - 50))\n",
    "        if i < len(d):\n",
    "            ax.text(d[i]*1.4, me[i], f'{s * 100:.3f}%' , fontsize=10,\n",
    "                    rotation=45, color='black', ha='right')\n",
    "\n",
    "    ax.set_xlim([5e-3, 1])\n",
    "    ax.set_ylim([1, 1e4])\n",
    "    ax.grid(True, which='both', linestyle='-', alpha=0.75)\n",
    "    ax.set_xlabel(\"Taille des plus gros fragments (cm)\")\n",
    "    ax.set_ylabel(\"Masse de l'√©chantillon (g)\")\n",
    "    ax.set_title(f\"Abaque de Gy ‚Äì al={al}, da={da}, dg={dg}, d0={d0}, ml={ml:.0f}\")\n",
    "   \n",
    "# Liste des widgets pour les √©tapes\n",
    "steps = []\n",
    "rows = VBox()\n",
    "output = Output()\n",
    "status_label = Label(value='')\n",
    "\n",
    "def add_step(_=None):\n",
    "    me_input = FloatText(description='me (g)', value=100.0, step=1.0, layout={'width': '160px'})\n",
    "    ml_input = FloatText(description='ml (g)', value=1000.0, step=1.0, layout={'width': '160px'})\n",
    "    d_input = FloatText(description='d (cm)', value=0.1, step=0.01, layout={'width': '160px'})\n",
    "    \n",
    "    steps.append((me_input, ml_input, d_input))\n",
    "    row = HBox([me_input, ml_input, d_input])\n",
    "    rows.children += (row,)\n",
    "    \n",
    "    me_input.observe(update_plot, names='value')\n",
    "    ml_input.observe(update_plot, names='value')\n",
    "    d_input.observe(update_plot, names='value')\n",
    "    \n",
    "    update_plot()\n",
    "\n",
    "def remove_step(_=None):\n",
    "    if steps:\n",
    "        steps.pop()\n",
    "        rows.children = rows.children[:-1]\n",
    "        update_plot()\n",
    "\n",
    "def finish_steps(_=None):\n",
    "    btn_add.disabled = True\n",
    "    btn_finish.disabled = True\n",
    "    status_label.value = \"Fin de la saisie des √©tapes. Plus aucune √©tape ne peut √™tre ajout√©e.\"\n",
    "    update_plot()\n",
    "\n",
    "def update_params(_=None):\n",
    "    try:\n",
    "        params['al'] = float(al_input.value)\n",
    "        params['da'] = float(da_input.value)\n",
    "        params['dg'] = float(dg_input.value)\n",
    "        params['d0'] = float(d0_input.value)\n",
    "    except Exception as e:\n",
    "        print(\"Erreur de saisie dans les param√®tres globaux:\", e)\n",
    "    update_plot()\n",
    "\n",
    "def update_plot(_=None):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        # Appliquer la contrainte ml_i+1 = me_i\n",
    "        update_ml_from_me()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        \n",
    "        d_vals = np.logspace(-2, 1, 100)\n",
    "        me_vals = np.logspace(1, 4, 100)\n",
    "        D, ME = np.meshgrid(d_vals, me_vals)\n",
    "        \n",
    "        SR = np.zeros_like(D)\n",
    "        for i in range(D.shape[0]):\n",
    "            for j in range(D.shape[1]):\n",
    "                SR[i, j] = gy(params['al'], params['da'], params['dg'], ME[i, j], params['d0'], me=ME[i, j], d=D[i, j])\n",
    "        \n",
    "        cs = ax.contour(D, ME, SR * 100, levels=[5, 10, 20, 40, 60, 80], colors='gray', linestyles='dashed')\n",
    "        ax.clabel(cs, inline=True, fontsize=8, fmt='%1.0f%%')\n",
    "        \n",
    "        sr_list = []\n",
    "        valid_coords = []\n",
    "        ml_values = []\n",
    "        \n",
    "        for (me_input, ml_input, d_input) in steps:\n",
    "            me = me_input.value\n",
    "            ml = ml_input.value\n",
    "            d = d_input.value\n",
    "            if me > 0 and ml > 0 and d > 0:\n",
    "                sr = gy(params['al'], params['da'], params['dg'], ml, params['d0'], me, d)\n",
    "                if np.isnan(sr):\n",
    "                    continue\n",
    "                sr_list.append(sr)\n",
    "                ml_values.append(ml)\n",
    "                ax.plot(d, me, 'ro')\n",
    "                ax.text(d * 1.1, me * 1.1, f'{sr * 100:.3f}%', fontsize=9, color='red')\n",
    "                valid_coords.append((d, me))\n",
    "        \n",
    "        for i in range(len(valid_coords) - 1):\n",
    "            x1, y1 = valid_coords[i]\n",
    "            x2, y2 = valid_coords[i+1]\n",
    "            ax.add_patch(FancyArrowPatch((x1, y1), (x2, y1), arrowstyle='->', color='blue', mutation_scale=12, lw=1.5))\n",
    "            ax.add_patch(FancyArrowPatch((x2, y1), (x2, y2), arrowstyle='->', color='blue', mutation_scale=12, lw=1.5))\n",
    "        \n",
    "        ax.set_xlabel('Taille max fragments d (cm)')\n",
    "        ax.set_ylabel('Masse √©chantillon me (g)')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlim(5e-3, 100)\n",
    "        ax.set_ylim(10, 1e4)\n",
    "        ax.grid(True, which='both')\n",
    "        ax.set_title('Abaque de Gy - √âcarts-types relatifs par √©tape')\n",
    "        \n",
    "        sr_global = None\n",
    "        if sr_list:\n",
    "            sr_global = np.sqrt(np.sum(np.array(sr_list) ** 2))\n",
    "            ax.text(0.02, 0.9 * ax.get_ylim()[1], f\"sr global = {sr_global * 100:.3f}%\", color='blue', fontsize=12)\n",
    "        \n",
    "        ml_moyen = np.max(ml_values) if ml_values else 1000\n",
    "        \n",
    "        plot_gy_iso_contours(ax, params['al'], params['da'], params['dg'], params['d0'],\n",
    "                             ml=ml_moyen, s_vals=[0.001, 0.005, 0.01, 0.05, 0.1, 0.2])\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        # Affichage des valeurs Sr par √©tape dans la sortie texte\n",
    "        if sr_list:\n",
    "            print(\"\\nValeurs des Sr par √©tape :\")\n",
    "            print(\"(Ligne 1 = 1er √©chantillon, Ligne 2 = 2√®me, etc.)\\n\")\n",
    "            for i, sr_val in enumerate(sr_list, 1):\n",
    "                print(f\"Sr{i} = {sr_val*100:.3f} %\")\n",
    "            print(f\"\\nSr global = {sr_global*100:.3f} %\")\n",
    "        \n",
    "        # Validation du sr global si d√©fini\n",
    "        if sr_global is not None:\n",
    "            sr_desire = sr_desire_input.value / 100\n",
    "            if sr_global <= sr_desire:\n",
    "                validation_label.value = f\"‚úÖ Proc√©dure valide (sr_global = {sr_global*100:.3f}% ‚â§ sr d√©sir√© = {sr_desire*100:.3f}%)\"\n",
    "                validation_label.color = 'green'\n",
    "            else:\n",
    "                validation_label.value = f\"‚ùå Proc√©dure NON valide (sr_global = {sr_global*100:.3f}% > sr d√©sir√© = {sr_desire*100:.3f}%)\"\n",
    "                validation_label.color = 'red'\n",
    "        else:\n",
    "            validation_label.value = \"\"\n",
    "\n",
    "btn_add = Button(description='Ajouter √©tape', button_style='success')\n",
    "btn_add.on_click(add_step)\n",
    "\n",
    "btn_remove = Button(description='Supprimer derni√®re √©tape', button_style='warning')\n",
    "btn_remove.on_click(remove_step)\n",
    "\n",
    "btn_finish = Button(description='Fin', button_style='danger')\n",
    "btn_finish.on_click(finish_steps)\n",
    "\n",
    "al_input.observe(update_params, names='value')\n",
    "da_input.observe(update_params, names='value')\n",
    "dg_input.observe(update_params, names='value')\n",
    "d0_input.observe(update_params, names='value')\n",
    "\n",
    "\n",
    "ui = VBox([\n",
    "    Label(\"Param√®tres globaux :\"), \n",
    "    params_widgets,\n",
    "    HBox([Label(\"sr d√©sir√© (%) :\"), sr_desire_input]),\n",
    "    HBox([btn_add, btn_remove, btn_finish]), \n",
    "    rows, \n",
    "    status_label,\n",
    "    validation_label,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7b7fb-4268-46e3-89f0-37a926baa8bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## üß™ Analyse des blancs ‚Äì Visualisation et interpr√©tation\n",
    "\n",
    "Ce graphique repr√©sente une s√©rie temporelle de mesures de blancs analytiques, c‚Äôest-√†-dire des √©chantillons cens√©s ne contenir aucun √©l√©ment d√©tectable.  \n",
    "Ces mesures sont utilis√©es pour v√©rifier la qualit√© des analyses et d√©tecter d‚Äô√©ventuelles contaminations.\n",
    "\n",
    "### üéØ Objectifs de l‚Äôexercice :\n",
    "\n",
    "- Visualiser les blancs dans l‚Äôordre d‚Äôanalyse.\n",
    "- Contr√¥ler la variabilit√© des mesures √† l‚Äôaide de bandes d‚Äôerreur statistiques (¬±1LD, ¬±2LD, ¬±3LD). LD est la limite de d√©tection de l'appareil, il est courant de bas√© la mesure d'erreur sur cette valeur. Des fois, on se basse sur un pourcentage de la teneur de coupure, p.ex, 5% t.c..\n",
    "- Identifier les valeurs aberrantes (hors de la distribution normale attendue).\n",
    "- Comparer les mesures aux seuils d‚Äôacceptabilit√© :\n",
    "  - Seuils bas√©s sur la limite de d√©tection (LD) : 3LD, 5LD, 10LD.\n",
    "  - Seuils relatifs √† la teneur de coupure : 5% et 10%.\n",
    "\n",
    "### üìä Ce que montre le graphique :\n",
    "\n",
    "- Les points verts repr√©sentent les mesures des blancs.\n",
    "- Les bandes vertes autour de la ligne de base (0 ppm) indiquent les intervalles de confiance statistiques.\n",
    "- Les lignes bleues sont les seuils de contr√¥le utilis√©s pour d√©tecter les √©checs.\n",
    "- Les points rouges signalent les valeurs aberrantes.\n",
    "- Le nombre de valeurs d√©passant la limite de d√©tection est affich√© dans le titre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8407ec2-1bde-4a20-87b8-a2e8df9bceaf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5436c5c669644d1b1c3b31e50199782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='Niveau de bruit', max=5.0, min=0.1), FloatSlider(val‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_blank_series(noise_level=1, standard_error=1)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "def generate_blank_series(n_points=1000, noise_level=1.0):\n",
    "    # Le bruit des blancs est g√©n√©r√© par une gaussien tronqu√©, c'est`√† dire que les valeurs inf√©rieures √† 0 sont amen√©es √† 0.\n",
    "    t = np.arange(n_points)\n",
    "    base = 0.0\n",
    "    noise = np.random.normal(0, noise_level, size=n_points)\n",
    "    series = base + noise\n",
    "    series = np.clip(series, 0, None)  # Pas de teneur n√©gative\n",
    "    return t, series\n",
    "\n",
    "def plot_blank_series(noise_level=1, standard_error=1):\n",
    "    np.random.seed(42)\n",
    "    n_points = 1000\n",
    "    t, blancs = generate_blank_series(n_points=n_points, noise_level=noise_level)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Trac√© des blancs\n",
    "    plt.plot(t, blancs, label=\"Blancs mesur√©s\", color='green', linestyle='', marker='x')\n",
    "\n",
    "    base_blanc = np.zeros_like(t)\n",
    "\n",
    "    # Zones ¬±3LD, ¬±5LD, ¬±10LD\n",
    "    limits = [3, 5, 10]\n",
    "    alphas = [0.3, 0.2, 0.1]\n",
    "\n",
    "    for k, alpha in zip(limits, alphas):\n",
    "        lower_bound = np.maximum(base_blanc - k * standard_error, 0)  # Ne pas descendre sous 0\n",
    "        upper_bound = base_blanc + k * standard_error\n",
    "        plt.fill_between(t, lower_bound, upper_bound,\n",
    "                         color='green', alpha=alpha, label=f'+{k} LD')\n",
    "\n",
    "    plt.plot(t, base_blanc, color='green', linestyle='--', label=\"Teneur attendue (blanc)\")\n",
    "\n",
    "    # D√©tection des outliers\n",
    "    diff = blancs - base_blanc  # Comme base = 0, c'est juste blancs\n",
    "    circle_sizes = 50\n",
    "\n",
    "    # Pr√©parer couleurs vides et on remplit selon seuils\n",
    "    colors = np.array(['none'] * len(diff))\n",
    "\n",
    "    # Seuils pour outliers\n",
    "    idx_3LD = diff > 10 * standard_error\n",
    "    idx_2LD = (diff > 5 * standard_error) & (~idx_3LD)\n",
    "    idx_1LD = (diff > 3 * standard_error) & (~idx_2LD) & (~idx_3LD)\n",
    "\n",
    "    # Assignation des couleurs\n",
    "    colors[idx_1LD] = '#ff4d4d'  # rouge clair vif\n",
    "    colors[idx_2LD] = '#cc0000'  # rouge moyen fonc√©\n",
    "    colors[idx_3LD] = '#660000'  # rouge tr√®s fonc√©\n",
    "\n",
    "    # Filtrer pour ne garder que les outliers\n",
    "    outlier_indices = np.where(colors != 'none')[0]\n",
    "\n",
    "    if outlier_indices.size > 0:\n",
    "        plt.scatter(t[outlier_indices], blancs[outlier_indices],\n",
    "                    s=circle_sizes,\n",
    "                    color=colors[outlier_indices],\n",
    "                    label=\"Outliers d√©tect√©s\",\n",
    "                    edgecolors='black', linewidths=0.7,\n",
    "                    alpha=0.9)\n",
    "\n",
    "    # Compter les outliers\n",
    "    count_1LD = np.sum(idx_1LD)\n",
    "    count_2LD = np.sum(idx_2LD)\n",
    "    count_3LD = np.sum(idx_3LD)\n",
    "    total_outliers = count_1LD + count_2LD + count_3LD\n",
    "\n",
    "    # Ajouter le compteur au titre\n",
    "    plt.title(f\"S√©rie temporelle des blancs avec limites de d√©tection et d√©tection automatique des outliers\\n\"\n",
    "              f\"Total outliers: {total_outliers} (1LD: {count_1LD}, 2LD: {count_2LD}, 3LD: {count_3LD})\")\n",
    "\n",
    "    plt.xlabel(\"Temps (√©chantillon)\")\n",
    "    plt.ylabel(\"Teneur (ppm)\")\n",
    "    plt.ylim(-0.5, 30 * standard_error)  # Axe y fix√© √† 30 fois LD\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    plot_blank_series,\n",
    "    noise_level=FloatSlider(value=1.0, min=0.1, max=5.0, step=0.1, description=\"Niveau de bruit\"),\n",
    "    standard_error=FloatSlider(value=0.5, min=0.1, max=5.0, step=0.1, description=\"Limite de d√©tection (LD)\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3152d-d879-47bf-8c22-cd78bba2ca5d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üî¨ Contr√¥le Qualit√© des S√©ries de Standards en Laboratoire\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Introduction\n",
    "\n",
    "Dans ce notebook, nous explorons des concepts cl√©s du **contr√¥le qualit√©** appliqu√© aux mesures r√©p√©t√©es de standards analytiques, notamment :\n",
    "\n",
    "- üß™ **G√©n√©ration simul√©e** de s√©ries temporelles de mesures standards, int√©grant diff√©rents types d‚Äôanomalies fr√©quentes en laboratoire (erreurs de transcription, changements de m√©thode, tendances).\n",
    "- üîç **D√©tection automatique d‚Äôanomalies** √† partir des r√®gles statistiques classiques bas√©es sur les √©carts types (¬±1œÉ, ¬±2œÉ, ¬±3œÉ) et leur interpr√©tation.\n",
    "- üìä **Visualisation interactive** permettant d‚Äôexplorer l‚Äôimpact des diff√©rents param√®tres (niveau de bruit, nombre et amplitude des erreurs, changement de m√©thode) sur la qualit√© des mesures et la robustesse des contr√¥les statistiques.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectifs p√©dagogiques\n",
    "\n",
    "√Ä la fin de cette s√©ance, vous serez capable de :\n",
    "\n",
    "- ‚ö†Ô∏è Comprendre les sources potentielles d‚Äôanomalies dans une s√©rie de mesures r√©p√©t√©es d‚Äôun standard.\n",
    "- üìè Appliquer des r√®gles de contr√¥le statistique pour identifier ces anomalies.\n",
    "- üìà Interpr√©ter graphiquement les r√©sultats de la d√©tection d‚Äôanomalies.\n",
    "- üïπÔ∏è Utiliser des widgets interactifs pour simuler diff√©rents sc√©narios et mieux appr√©hender la variabilit√© naturelle et les d√©viations anormales.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç D√©tection automatique des anomalies (r√®gles de Western Electric)\n",
    "\n",
    "Bas√©e sur la moyenne (Œº) et l‚Äô√©cart-type (œÉ), 4 r√®gles empiriques d√©tectent les signaux d‚Äôun processus potentiellement hors de contr√¥le :\n",
    "\n",
    "**Liste des crit√®res**\n",
    "1. **Un point au-del√† de ¬±3œÉ**  \n",
    "   \\(|x - \\mu| > 3\\sigma\\) ‚Üí Anomalie majeure  \n",
    "   Probabilit√© ‚âà 0.27 % ‚Äî signal fort d‚Äôun √©v√©nement exceptionnel.\n",
    "\n",
    "2. **Deux points cons√©cutifs au-del√† de ¬±2œÉ, du m√™me c√¥t√©**  \n",
    "   \\(x_1, x_2 > \\mu + 2\\sigma\\) ou \\(< \\mu - 2\\sigma\\) ‚Üí Biais temporaire suspect√©  \n",
    "   Seuil d‚Äôalerte ‚âà 1 % (valeur empirique).\n",
    "\n",
    "3. **Quatre points cons√©cutifs au-del√† de ¬±1œÉ, du m√™me c√¥t√©**  \n",
    "   \\(x_1, ..., x_4 > \\mu + \\sigma\\) ou \\(< \\mu - \\sigma\\) ‚Üí D√©rive progressive  \n",
    "   Seuil d‚Äôalerte ‚âà 1 % (valeur empirique).\n",
    "\n",
    "4. **Huit points cons√©cutifs du m√™me c√¥t√© de la moyenne (Œº)**  \n",
    "   \\(x_1, ..., x_8 > \\mu\\) ou \\(< \\mu\\) ‚Üí Changement syst√©matique  \n",
    "   Seuil d‚Äôalerte ‚âà 1 % (valeur empirique).\n",
    "\n",
    "---\n",
    "\n",
    "> üß† *Ces seuils sont empiriques, choisis pour un bon compromis entre d√©tection d‚Äôanomalies et faux positifs, et peuvent diff√©rer des calculs th√©oriques sous hypoth√®ses normale.*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0116e3ea-5c3e-4e1c-9aa4-f07d13af5565",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180a4b3e54534339b7ce37d88e8b47f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.2, description='Zone erreurs d√©but', max=0.5, min=0.05, step=0.05), ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_standard_series(error_zone_fraction, noise_level, standard_error, trend_slope, n_transcription_errors, transcription_error_magnitude, method_change, method_change_point, method_change_magnitude)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, FloatSlider, Checkbox\n",
    "\n",
    "def generate_standard_series(\n",
    "    n_points=500,\n",
    "    noise_level=1.0,\n",
    "    trend_slope=0.0,\n",
    "    n_transcription_errors=0,\n",
    "    transcription_error_magnitude=2.0,\n",
    "    method_change=False,\n",
    "    method_change_point=250,\n",
    "    method_change_magnitude=5.0,\n",
    "    error_zone_fraction=0.2\n",
    "):\n",
    "    t = np.arange(n_points)\n",
    "    base = 50 + trend_slope * (t - round(len(t)/2))\n",
    "    noise = np.random.normal(0, noise_level, size=n_points)\n",
    "    series = base + noise\n",
    "\n",
    "    max_index_for_errors = int(n_points * error_zone_fraction)\n",
    "\n",
    "    if n_transcription_errors > 0 and max_index_for_errors > 0:\n",
    "        indices = np.random.choice(max_index_for_errors, size=n_transcription_errors, replace=False)\n",
    "        errors = np.random.choice([-1, 1], size=n_transcription_errors) * transcription_error_magnitude\n",
    "        series[indices] += errors\n",
    "\n",
    "    if method_change:\n",
    "        series[method_change_point:] += method_change_magnitude\n",
    "\n",
    "    return t, series\n",
    "\n",
    "def detect_anomalies(series, mean, std):\n",
    "    n = len(series)\n",
    "    anomalies = {\n",
    "        \"Crit√®re 1\": [],\n",
    "        \"Crit√®re 2\": [],\n",
    "        \"Crit√®re 3\": [],\n",
    "        \"Crit√®re 4\": [],\n",
    "    }\n",
    "\n",
    "    for i in range(n):\n",
    "        if abs(series[i] - mean) > 3 * std:\n",
    "            anomalies[\"Crit√®re 1\"].append(i)\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        cond1 = (series[i] - mean) > 2 * std and (series[i+1] - mean) > 2 * std\n",
    "        cond2 = (series[i] - mean) < -2 * std and (series[i+1] - mean) < -2 * std\n",
    "        if cond1 or cond2:\n",
    "            anomalies[\"Crit√®re 2\"].extend([i, i+1])\n",
    "\n",
    "    side = np.sign(series - mean)\n",
    "    outside_1sigma = np.abs(series - mean) > std\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        if outside_1sigma[i]:\n",
    "            if i == 0 or (side[i] == side[i-1] and side[i] != 0):\n",
    "                count += 1\n",
    "            else:\n",
    "                count = 1\n",
    "        else:\n",
    "            count = 0\n",
    "        if count >= 4:\n",
    "            anomalies[\"Crit√®re 3\"].append(i)\n",
    "\n",
    "    count_8 = 0\n",
    "    for i in range(n):\n",
    "        if i == 0 or (side[i] == side[i-1] and side[i] != 0):\n",
    "            count_8 += 1\n",
    "        else:\n",
    "            count_8 = 1\n",
    "        if count_8 >= 8:\n",
    "            anomalies[\"Crit√®re 4\"].append(i)\n",
    "\n",
    "    return anomalies\n",
    "\n",
    "def plot_standard_series(\n",
    "    error_zone_fraction,\n",
    "    noise_level,\n",
    "    standard_error,\n",
    "    trend_slope,\n",
    "    n_transcription_errors,\n",
    "    transcription_error_magnitude,\n",
    "    method_change,\n",
    "    method_change_point,\n",
    "    method_change_magnitude,\n",
    "):\n",
    "    np.random.seed(42)\n",
    "    t, series = generate_standard_series(\n",
    "        noise_level=noise_level,\n",
    "        trend_slope=trend_slope,\n",
    "        n_transcription_errors=n_transcription_errors,\n",
    "        transcription_error_magnitude=transcription_error_magnitude,\n",
    "        method_change=method_change,\n",
    "        method_change_point=method_change_point,\n",
    "        method_change_magnitude=method_change_magnitude,\n",
    "        error_zone_fraction=error_zone_fraction,\n",
    "    )\n",
    "\n",
    "    base_line = 50 + 0 * t\n",
    "    anomalies = detect_anomalies(series, mean=50.0, std=standard_error)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(t, series, label=\"Standard mesur√©\", color='blue', linestyle='', marker='*')\n",
    "\n",
    "    colors = ['#ffcc80', '#ffb74d', '#ffa726']\n",
    "    alphas = [0.3, 0.2, 0.1]\n",
    "    for k, alpha, color in zip([1, 2, 3], alphas, colors):\n",
    "        plt.fill_between(\n",
    "            t,\n",
    "            base_line - k * standard_error,\n",
    "            base_line + k * standard_error,\n",
    "            color=color,\n",
    "            alpha=alpha,\n",
    "            label=f'¬±{k}œÉ',\n",
    "            edgecolor=None,\n",
    "        )\n",
    "\n",
    "    plt.plot(t, base_line, color='orange', linestyle='--', label=\"Teneur attendue (50 ppm)\")\n",
    "\n",
    "    markers_info = {\n",
    "        \"Crit√®re 1\": (\"red\", 80, 'o'),\n",
    "        \"Crit√®re 2\": (\"purple\", 60, 's'),\n",
    "        \"Crit√®re 3\": (\"brown\", 50, '^'),\n",
    "        \"Crit√®re 4\": (\"green\", 40, 'D'),\n",
    "    }\n",
    "\n",
    "    for crit, (color, size, marker) in markers_info.items():\n",
    "        indices = list(set(anomalies[crit]))\n",
    "        plt.scatter(t[indices], series[indices], color=color, label=crit, s=size, marker=marker, edgecolors='k', zorder=5)\n",
    "\n",
    "    if method_change:\n",
    "        plt.axvline(method_change_point, color=\"red\", linestyle=\"--\", label=\"Changement m√©thode\")\n",
    "\n",
    "    plt.xlabel(\"Temps (√©chantillon)\")\n",
    "    plt.ylabel(\"Teneur standard (ppm)\")\n",
    "    plt.title(\"S√©rie temporelle de standards avec d√©tection d‚Äôanomalies (¬±œÉ)\")\n",
    "    plt.ylim(42, 58)\n",
    "\n",
    "    # L√©gende √† l'ext√©rieur √† droite\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=9)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # laisse la place pour la l√©gende\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    plot_standard_series,\n",
    "    error_zone_fraction=FloatSlider(value=0.2, min=0.05, max=0.5, step=0.05, description=\"Zone erreurs d√©but\"),\n",
    "    noise_level=FloatSlider(value=1.0, min=0.1, max=5.0, step=0.1, description=\"Niveau bruit\"),\n",
    "    standard_error=FloatSlider(value=1.0, min=0.5, max=2, step=0.1, description=\"Erreur type\"),\n",
    "    trend_slope=FloatSlider(value=0.0, min=-0.01, max=0.01, step=0.001, description=\"Tendance\"),\n",
    "    n_transcription_errors=IntSlider(value=0, min=0, max=20, step=1, description=\"Erreurs transcription\"),\n",
    "    transcription_error_magnitude=FloatSlider(value=2, min=1, max=4, step=0.01, description=\"Amplitude erreur\"),\n",
    "    method_change=Checkbox(value=False, description=\"Changement m√©thode\"),\n",
    "    method_change_point=IntSlider(value=250, min=1, max=499, step=1, description=\"Point changement\"),\n",
    "    method_change_magnitude=FloatSlider(value=0.0, min=-1, max=1, step=0.1, description=\"Amplitude changement\"),\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fcfa3-3bf4-422c-98c6-4610e6ff9c86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Simulation de QA/QC sur duplicatas g√©ochimiques avec incertitude contr√¥l√©e\n",
    "\n",
    "Cette section pr√©sente trois graphiques types couramment utilis√©s dans l‚Äô√©valuation des duplicatas en contr√¥le de la qualit√© (QA/QC).  \n",
    "Nous explorerons ensemble leurs points forts et leurs limites, en mettant en √©vidence ce qu‚Äôils permettent de d√©tecter ‚Äî ou non ‚Äî dans les √©carts entre duplicatas.\n",
    "\n",
    "### üìä 1. Nuage de points des duplicatas\n",
    "\n",
    "Ce graphique compare directement les deux s√©ries simul√©es de duplicatas.  \n",
    "- La ligne noire en pointill√© repr√©sente l‚Äô√©galit√© parfaite (Duplicata 1 = Duplicata 2).\n",
    "- Les bandes color√©es indiquent les tol√©rances acceptables de ¬±10%, ¬±20% et ¬±30%.\n",
    "- Les points rouges indiquent les cas o√π l‚Äô√©cart d√©passe ¬±10%, signalant un probl√®me potentiel de reproductibilit√©.\n",
    "\n",
    "Cela permet une √©valuation visuelle imm√©diate du respect des crit√®res QA/QC selon les tol√©rances d√©finies. Cependant, il n'est pas tr√®s informatif. On a recourd g√©n√©ralement aux graphiques des points 2 et 3.\n",
    "\n",
    "### üìà 2. Diff√©rence relative (%) selon la moyenne des duplicatas\n",
    "Ce graphique montre la diff√©rence relative entre les deux duplicatas en pourcentage, en fonction de leur moyenne :\n",
    "- Il met en √©vidence les √©carts syst√©matiques ou al√©atoires.\n",
    "- Les lignes pointill√©es indiquent les niveaux de tol√©rance.\n",
    "- Les points rouges signalent les duplicatas hors tol√©rance de ¬±10 %.\n",
    "\n",
    "Ce graphique permet d‚Äôidentifier si les √©carts entre duplicatas sont constants ou proportionnels √† l‚Äôintensit√© des valeurs ‚Äî un effet souvent appel√© *effet multiplicatif*.  \n",
    "On observe g√©n√©ralement que les faibles teneurs pr√©sentent des erreurs relatives plus √©lev√©es que les fortes teneurs.  \n",
    "Il est donc essentiel de porter une attention particuli√®re √† la zone autour de la teneur de coupure, o√π ces erreurs peuvent avoir un impact significatif sur les d√©cisions d‚Äôexploitation.\n",
    "\n",
    "\n",
    "### üìê 3. Courbe HARD (Half Absolute Relative Difference)\n",
    "\n",
    "Le graphique HARD trace la courbe cumulative de l‚Äôerreur relative :\n",
    "- Sur l‚Äôaxe vertical, on mesure l‚Äô√©cart relatif (|D1 ‚àí D2| / (D1 + D2)).\n",
    "- L‚Äôaxe horizontal correspond au rang normalis√© des points (i.e., leur position dans la distribution tri√©e).\n",
    "- Le point rouge repr√©sente un objectif typique (par ex. 90% des duplicatas dans ¬±10%).\n",
    "\n",
    "Ce graphique est souvent utilis√© pour √©valuer la **performance globale du protocole de QA/QC**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dcdc1c84-61a2-4448-9eea-a4be6309f08d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f815ec117a84f34b45647f681bea83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.9, description='M√©diane', max=10.0, min=0.1, step=0.001), FloatSlide‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_lognormal_variable_noise(median=2.0, sigma=0.4, corr=0.9, p=0.0)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "def generate_correlated_lognormal_series_mv_variable_noise(\n",
    "    n_points=100,\n",
    "    base_median=2,\n",
    "    sigma_base=0.4,\n",
    "    correlation=0.95,\n",
    "    p=0.0,  # nouveau param√®tre contr√¥le la pente du sigma selon la valeur\n",
    "):\n",
    "    mu = np.log(base_median)\n",
    "\n",
    "    # Tirage base_vals avec sigma fixe non nul (exemple 0.2)\n",
    "    base_vals = np.exp(np.random.normal(mu, 0.2, size=n_points))\n",
    "\n",
    "    safe_vals = np.clip(base_vals, 1e-3, None)\n",
    "    sigma_vals = sigma_base  # scalaire\n",
    "\n",
    "    corr_mat = np.array([[1.0, correlation],\n",
    "                         [correlation, 1.0]])\n",
    "\n",
    "    dup1 = np.empty(n_points)\n",
    "    dup2 = np.empty(n_points)\n",
    "    for i in range(n_points):\n",
    "        cov = corr_mat * sigma_vals**2  # <-- ici on utilise sigma_vals comme scalaire\n",
    "        noise = np.random.multivariate_normal(mean=[0, 0], cov=cov)\n",
    "        dup1[i] = np.exp(mu + noise[0])\n",
    "        dup2[i] = np.exp(mu + noise[1])\n",
    "\n",
    "    dup1 += np.random.normal(0, p, size=n_points)\n",
    "    dup2 += np.random.normal(0, p, size=n_points)\n",
    "\n",
    "    return dup1, dup2\n",
    "\n",
    "\n",
    "def plot_lognormal_variable_noise(median=2.0, sigma=0.4, corr=0.9, p=0.0):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    dup1, dup2 = generate_correlated_lognormal_series_mv_variable_noise(\n",
    "        n_points=200,\n",
    "        base_median=median,\n",
    "        sigma_base=sigma,\n",
    "        correlation=corr,\n",
    "        p=p,\n",
    "    )\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 6), constrained_layout=True)\n",
    "\n",
    "    max_val = min(max(np.quantile(dup1, 0.95), np.quantile(dup2, 0.95)) * 1.1, 100)\n",
    "\n",
    "    # --- Scatter duplicatas ---\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    ax1.scatter(dup1, dup2, alpha=0.6, label=\"Points\")\n",
    "\n",
    "    lims = [0, max_val]\n",
    "    ax1.plot(lims, lims, 'k--', label=\"y = x\")\n",
    "\n",
    "    tolerances = [0.1, 0.2, 0.3]\n",
    "    colors = ['r', 'orange', 'purple']\n",
    "\n",
    "    counts_out = []\n",
    "    for tol, col in zip(tolerances, colors):\n",
    "        lower = 1 - tol\n",
    "        upper = 1 + tol\n",
    "        ax1.plot(lims, [lims[0]*upper, lims[1]*upper], color=col, linestyle='-', alpha=0.6, label=f\"¬±{int(tol*100)}%\")\n",
    "        ax1.plot(lims, [lims[0]*lower, lims[1]*lower], color=col, linestyle='-', alpha=0.6)\n",
    "        out_of_bounds = (dup2 < dup1 * lower) | (dup2 > dup1 * upper)\n",
    "        counts_out.append(np.sum(out_of_bounds))\n",
    "\n",
    "    tol_max = 0.1\n",
    "    lower_max = 1 - tol_max\n",
    "    upper_max = 1 + tol_max\n",
    "    out_max = (dup2 < dup1 * lower_max) | (dup2 > dup1 * upper_max)\n",
    "    ax1.scatter(dup1[out_max], dup2[out_max], color='red', s=80, label='Hors ¬±10%')\n",
    "\n",
    "    median_r = round(median, 2)\n",
    "    sigma_r = round(sigma, 2)\n",
    "    corr_r = round(corr, 2)\n",
    "    p_r = round(p, 2)\n",
    "\n",
    "    ax1.set_xlabel(\"Duplicata 1\")\n",
    "    ax1.set_ylabel(\"Duplicata 2\")\n",
    "    ax1.set_title(f\"S√©ries lognormales corr√©l√©es\\nM√©diane={median_r}, Sigma={sigma_r}, Corr={corr_r}, p={p_r}\\n\"\n",
    "              f\"Hors ¬±10%: {counts_out[0]} | ¬±20%: {counts_out[1]} | ¬±30%: {counts_out[2]} sur {len(dup1)} points\")\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.set_xlim(0, max_val)\n",
    "    ax1.set_ylim(0, max_val)\n",
    "\n",
    "    # --- Diff√©rence relative ---\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    mean_vals = (dup1 + dup2) / 2\n",
    "    diff_rel = 100 * (dup1 - dup2) / mean_vals\n",
    "\n",
    "    ax2.scatter(mean_vals, diff_rel, alpha=0.6, color='blue', label=\"Diff√©rence relative (%)\")\n",
    "\n",
    "    for tol, col in zip(tolerances, colors):\n",
    "        ax2.axhline(y=tol*100, color=col, linestyle='--', alpha=0.6, label=f'¬±{int(tol*100)}%')\n",
    "        ax2.axhline(y=-tol*100, color=col, linestyle='--', alpha=0.6)\n",
    "\n",
    "    out_diff_max = (diff_rel > 10) | (diff_rel < -10)\n",
    "    ax2.scatter(mean_vals[out_diff_max], diff_rel[out_diff_max], color='red', s=80, label='Hors ¬±10%')\n",
    "\n",
    "    ax2.set_xlabel(\"(Duplicata 1 + Duplicata 2) / 2\")\n",
    "    ax2.set_ylabel(\"Diff√©rence relative (%)\")\n",
    "    ax2.set_title(\"Diff√©rence relative entre duplicatas\")\n",
    "    ax2.grid(True)\n",
    "    ax2.legend(loc='best')\n",
    "    ax2.set_xlim(0, max_val)\n",
    "    ax2.set_ylim(-50, 50)\n",
    "\n",
    "    # --- HARD plot ---\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    N = len(dup1)\n",
    "    hard_vals = np.sort(np.abs(dup1 - dup2) / (dup1 + dup2))\n",
    "    ranks = np.arange(1, N + 1) / (N + 1)\n",
    "\n",
    "    ax3.plot(ranks, hard_vals, color='black', linewidth=2, label='Cible')\n",
    "    ax3.plot(0.9, 0.1, 'o', color='red', markersize=10, label='Point critique')\n",
    "    ax3.set_xlabel('Rang/(N+1)')\n",
    "    ax3.set_ylabel('Graphique HARD')\n",
    "    ax3.set_ylim(0, max(0.3, hard_vals.max() * 1.1))  # plus flexible\n",
    "    ax3.grid(True)\n",
    "    ax3.legend(loc='best')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(\n",
    "    plot_lognormal_variable_noise,\n",
    "    median=FloatSlider(min=0.1, max=10, step=0.001, value=0.9, description=\"M√©diane\"),\n",
    "    sigma=FloatSlider(min=0.05, max=1.0, step=0.001, value=1.4, description=\"Sigma base\"),\n",
    "    corr=FloatSlider(min=0.95, max=0.999, step=0.001, value=0.996, description=\"Corr√©lation\", readout_format=\".3f\"),\n",
    "    p=FloatSlider(min=0, max=2.0, step=0.05, value=0, description=\"Bruit d√©croissant p\")\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
