{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def46c11-5717-4c21-94a5-0d6103b4abc2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danyl\\anaconda3\\envs\\glq-book\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51a378-459a-4ff9-b98e-58c4ded5ce78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Atelier 2 - D√©groupement\n",
    "\n",
    "## üìò Analyse du D√©groupement sur un Gisement Synth√©tique Spatialement Corr√©l√©\n",
    "\n",
    "Dans cet atelier, nous explorerons les effets de l'√©chantillonnage et du d√©groupement sur un gisement spatialement corr√©l√© suivant une distribution marginale log-normale. Nous analyserons comment la taille des cellules de d√©groupement influence les estimations de la moyenne et de la variance des √©chantillons. Les participants apprendront √† visualiser et interpr√©ter les r√©sultats √† travers des graphiques interactifs.\n",
    "\n",
    "### üñºÔ∏è Descriptions des 4 figures\n",
    "\n",
    "1. **Carte du champ log-normal avec √©chantillons :**  \n",
    "   Cette figure montre la distribution spatiale du champ log-normal simul√©, avec les emplacements des √©chantillons al√©atoires (en noir) et ceux ciblant une zone √† forte valeur (hotspot, en rouge).\n",
    "\n",
    "2. **Histogrammes et fonctions de r√©partition cumul√©e (CDF) :**  \n",
    "   On compare ici la distribution des valeurs du champ complet avec celles des √©chantillons, en incluant une version pond√©r√©e si le d√©groupement est activ√©, pour visualiser les biais d‚Äô√©chantillonnage.\n",
    "\n",
    "3. **Effet de la taille de cellule sur la moyenne pond√©r√©e :**  \n",
    "   Cette courbe montre comment la moyenne des √©chantillons varie en fonction de la taille des cellules utilis√©es pour le d√©groupement, compar√©e √† la moyenne globale du champ.\n",
    "\n",
    "4. **Effet de la taille de cellule sur la variance pond√©r√©e :**  \n",
    "   De mani√®re similaire, cette figure illustre l‚Äôimpact de la taille de cellule sur la variance estim√©e des √©chantillons, en la comparant √† la variance r√©elle du champ.\n",
    "\n",
    "\n",
    "üìù Note : Apr√®s chaque modification des param√®tres, cliquez sur le bouton \"Tracer\" (en bleu) pour actualiser les figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9b2121-62ff-4400-aee2-8a1f3fd6301e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb80e78e354949f888f011ddabf817e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntText(value=50, description='Port√©e', layout=Layout(width='180px')), FloatText‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# === Fonctions principales ===\n",
    "def spherical_cov(h, range_):\n",
    "    c = np.zeros_like(h)\n",
    "    mask = h < range_\n",
    "    hr = h[mask] / range_\n",
    "    c[mask] = 1 - 1.5 * hr + 0.5 * hr**3\n",
    "    return c\n",
    "\n",
    "def fftma_spherical(n, range_, sigma=1.0, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    N = 2 * n\n",
    "    x = np.arange(N)\n",
    "    y = np.arange(N)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    dist_x = np.minimum(X, N - X)\n",
    "    dist_y = np.minimum(Y, N - Y)\n",
    "    h = np.sqrt(dist_x**2 + dist_y**2)\n",
    "    cov = spherical_cov(h, range_)\n",
    "    cov = cov / cov.max()\n",
    "    fft_cov = np.fft.fft2(cov)\n",
    "    white_noise = np.random.normal(0, 1, (N, N))\n",
    "    fft_noise = np.fft.fft2(white_noise)\n",
    "    fft_field = np.sqrt(np.abs(fft_cov)) * fft_noise\n",
    "    field = np.fft.ifft2(fft_field).real\n",
    "    field = field[:n, :n]\n",
    "    field = (field - np.mean(field)) / np.std(field)\n",
    "    field = field * sigma\n",
    "    return field\n",
    "\n",
    "def generate_field(n, range_, mean=1.0, var=1.0, seed=None, distribution='lognormal'):\n",
    "    \"\"\"G√©n√®re un champ normal ou log-normal avec moyenne et variance exactes.\"\"\"\n",
    "    gauss_field = fftma_spherical(n, range_, sigma=1.0, seed=seed)\n",
    "    if distribution == 'normal':\n",
    "        field = mean + np.sqrt(var) * gauss_field\n",
    "    elif distribution == 'lognormal':\n",
    "        sigma_ln = np.sqrt(np.log(1 + var / mean**2))\n",
    "        mu_ln = np.log(mean) - 0.5 * sigma_ln**2\n",
    "        field = np.exp(mu_ln + sigma_ln * gauss_field)\n",
    "    else:\n",
    "        raise ValueError(\"distribution doit √™tre 'normal' ou 'lognormal'\")\n",
    "    return gauss_field, field\n",
    "\n",
    "def compute_cell_declustering_weights(samples, n_cells):\n",
    "    cells = {}\n",
    "    weights = np.zeros(len(samples))\n",
    "    for i, (x, y) in enumerate(samples):\n",
    "        cx = int(x / n_cells)\n",
    "        cy = int(y / n_cells)\n",
    "        key = (cx, cy)\n",
    "        if key not in cells:\n",
    "            cells[key] = []\n",
    "        cells[key].append(i)\n",
    "    for indices in cells.values():\n",
    "        w = 1.0 / len(indices)\n",
    "        for idx in indices:\n",
    "            weights[idx] = w\n",
    "    return weights\n",
    "\n",
    "def find_specialspot_location(field, spot_size, spot_type='hotspot'):\n",
    "    n = field.shape[0]\n",
    "    if spot_type == 'hotspot':\n",
    "        pos = np.unravel_index(np.argmax(field), field.shape)\n",
    "    elif spot_type == 'coldspot':\n",
    "        pos = np.unravel_index(np.argmin(field), field.shape)\n",
    "    else:\n",
    "        raise ValueError(\"spot_type doit √™tre 'hotspot' ou 'coldspot'\")\n",
    "    x0 = max(0, pos[0] - spot_size // 2)\n",
    "    y0 = max(0, pos[1] - spot_size // 2)\n",
    "    x1 = min(n, x0 + spot_size)\n",
    "    y1 = min(n, y0 + spot_size)\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "def interactive_sampling_fixed_spot(\n",
    "    n, range_, mean, var, n_samples_all,\n",
    "    n_samples_spot, spot_size, declust_cells,\n",
    "    show_declustering, seed, spot_type, distribution\n",
    "):\n",
    "    gauss_field, field = generate_field(n, range_, mean=mean, var=var, seed=seed, distribution=distribution)\n",
    "\n",
    "    # D√©finir hotspot/coldspot\n",
    "    x0, y0, x1, y1 = find_specialspot_location(field, spot_size, spot_type=spot_type)\n",
    "\n",
    "    # Coordonn√©es indices\n",
    "    indices_all = np.array([(i,j) for i in range(n) for j in range(n)])\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # √âchantillons al√©atoires hors spot\n",
    "    sampled_indices_all = rng.choice(len(indices_all), size=n_samples_all, replace=False)\n",
    "    samples_all = indices_all[sampled_indices_all]\n",
    "    samples_all_values = field[samples_all[:,0], samples_all[:,1]]\n",
    "\n",
    "    # √âchantillons dans le spot\n",
    "    indices_spot = np.array([(i,j) for i in range(x0, x1) for j in range(y0, y1)])\n",
    "    if len(indices_spot) == 0:\n",
    "        samples_spot = np.empty((0,2), dtype=int)\n",
    "        samples_spot_values = np.array([])\n",
    "    else:\n",
    "        n_samples_spot = min(n_samples_spot, len(indices_spot))\n",
    "        sampled_indices_spot = rng.choice(len(indices_spot), size=n_samples_spot, replace=False)\n",
    "        samples_spot = indices_spot[sampled_indices_spot]\n",
    "        samples_spot_values = field[samples_spot[:,0], samples_spot[:,1]]\n",
    "    \n",
    "    # Combiner √©chantillons\n",
    "    combined_samples = np.vstack([samples_all, samples_spot])\n",
    "    combined_values = np.concatenate([samples_all_values, samples_spot_values])\n",
    "\n",
    "    # D√©groupement avec plusieurs translations (debiaisement)\n",
    "    n_shifts = 5\n",
    "    def debiased_weights(samples, cell_size):\n",
    "        mean_list = []\n",
    "        for _ in range(n_shifts):\n",
    "            shift_x = rng.integers(0, cell_size)\n",
    "            shift_y = rng.integers(0, cell_size)\n",
    "            shifted = samples.copy()\n",
    "            shifted[:,0] = (shifted[:,0] + shift_x) % n\n",
    "            shifted[:,1] = (shifted[:,1] + shift_y) % n\n",
    "            w = compute_cell_declustering_weights(shifted, cell_size)\n",
    "            w /= w.sum()\n",
    "            mean_list.append(np.sum(w*combined_values))\n",
    "        return np.mean(mean_list)\n",
    "    \n",
    "    # Moyenne/variance pond√©r√©e vs taille cellule\n",
    "    cell_sizes = np.arange(1, n//2)\n",
    "    means = [debiased_weights(combined_samples, c) for c in cell_sizes]\n",
    "    variances = []\n",
    "    for c in cell_sizes:\n",
    "        var_list = []\n",
    "        for _ in range(n_shifts):\n",
    "            shift_x = rng.integers(0, c)\n",
    "            shift_y = rng.integers(0, c)\n",
    "            shifted = combined_samples.copy()\n",
    "            shifted[:,0] = (shifted[:,0] + shift_x) % n\n",
    "            shifted[:,1] = (shifted[:,1] + shift_y) % n\n",
    "            w = compute_cell_declustering_weights(shifted, c)\n",
    "            w /= w.sum()\n",
    "            mean_c = np.sum(w*combined_values)\n",
    "            var_list.append(np.sum(w*(combined_values - mean_c)**2))\n",
    "        variances.append(np.mean(var_list))\n",
    "\n",
    "    # === Affichage ===\n",
    "    fig, axs = plt.subplots(2,2, figsize=(10,8))\n",
    "\n",
    "    # Carte\n",
    "    ax = axs[0,0]\n",
    "    im = ax.imshow(field, cmap='jet', origin='lower')\n",
    "    ax.scatter(samples_all[:,1], samples_all[:,0], facecolors='none', edgecolors='black', s=40)\n",
    "    ax.scatter(samples_spot[:,1], samples_spot[:,0], facecolors='none', edgecolors='black', s=40)\n",
    "    ax.set_title(\"Gisement avec √©chantillons\") \n",
    "    ax.set_xlabel('X'); ax.set_ylabel('Y')\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04, label=f'Valeur {distribution}')\n",
    "\n",
    "    # Histogrammes & CDF\n",
    "    ax = axs[0,1]\n",
    "    bins = np.linspace(np.min(field), np.percentile(field,99.5),30)\n",
    "    sns.histplot(field.flatten(), bins=bins, stat=\"density\", color='gray', label='Champ complet', ax=ax, alpha=0.3)\n",
    "    sns.histplot(combined_values, bins=bins, stat=\"density\", color='blue', label='√âchantillons', ax=ax, alpha=0.4)\n",
    "    if show_declustering:\n",
    "        w = compute_cell_declustering_weights(combined_samples, declust_cells)\n",
    "        w /= w.sum()\n",
    "        ax.hist(combined_values, bins=bins, weights=w, density=True, color='green', alpha=0.5, edgecolor='black', linewidth=0.5, label='D√©group√©s')\n",
    "    ax.set_xlabel(\"Valeur\"); ax.set_ylabel(\"Densit√©\")\n",
    "    ax2 = ax.twinx()\n",
    "    sorted_all = np.sort(field.flatten())\n",
    "    sorted_non = np.sort(combined_values)\n",
    "    sorted_idx = np.argsort(combined_values)\n",
    "    cdf_all = np.linspace(0,1,len(sorted_all))\n",
    "    cdf_non = np.linspace(0,1,len(sorted_non))\n",
    "    cdf_w = np.cumsum(w[sorted_idx]) if show_declustering else np.zeros_like(cdf_non)\n",
    "    ax2.plot(sorted_all, cdf_all, 'k--', lw=2)\n",
    "    ax2.plot(sorted_non, cdf_non, 'b-', lw=2)\n",
    "    if show_declustering:\n",
    "        ax2.plot(sorted_non, cdf_w, 'g-', lw=2)\n",
    "    ax2.set_ylim(0,1); ax2.set_ylabel(\"CDF\")\n",
    "\n",
    "    # Moyenne pond√©r√©e\n",
    "    ax = axs[1,0]\n",
    "    ax.plot(cell_sizes, means, '-o', color='purple')\n",
    "    #ax.axvline(declust_cells, color='red', linestyle='--', label=f'Taille cellule={declust_cells}')\n",
    "    #ax.axhline(np.mean(combined_values), color='blue', linestyle='--', label='Moyenne non pond√©r√©e')\n",
    "    #ax.axhline(np.mean(field), color='black', linestyle=':', label='Moyenne globale')\n",
    "    ax.set_xlabel(\"Taille cellule\"); ax.set_ylabel(\"Moyenne pond√©r√©e\")\n",
    "    ax.grid(True); #ax.legend()\n",
    "\n",
    "    # Variance pond√©r√©e\n",
    "    ax = axs[1,1]\n",
    "    ax.plot(cell_sizes, variances, '-o', color='darkgreen')\n",
    "    #ax.axvline(declust_cells, color='red', linestyle='--')\n",
    "    #ax.axhline(np.var(combined_values), color='blue', linestyle='--', label='Variance non pond√©r√©e')\n",
    "    #ax.axhline(np.var(field), color='black', linestyle=':', label='Variance globale')\n",
    "    ax.set_xlabel(\"Taille cellule\"); ax.set_ylabel(\"Variance pond√©r√©e\")\n",
    "    ax.grid(True); #ax.legend()\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "# === Initialisation param√®tres ===\n",
    "_n = 100\n",
    "_range_ = 50\n",
    "_sigma = 0.6\n",
    "_mean = 2.0\n",
    "_seed = 42\n",
    "_spot_size = 25\n",
    "\n",
    "# === Widgets ===\n",
    "range_w = widgets.IntText(value=_range_, description=\"Port√©e\", layout=widgets.Layout(width='180px'))\n",
    "sigma_w = widgets.FloatText(value=_sigma, description=\"Variance\", layout=widgets.Layout(width='180px'))\n",
    "mean_w = widgets.FloatText(value=_mean, description=\"Moyenne\", layout=widgets.Layout(width='180px'))\n",
    "n_samples_all_w = widgets.IntText(value=100, description=\"N al√©atoire\", layout=widgets.Layout(width='180px'))\n",
    "n_samples_spot_w = widgets.IntText(value=50, description=\"N spot\", layout=widgets.Layout(width='180px'))\n",
    "declust_cells_w = widgets.IntText(value=10, description=\"Taille cellule\", layout=widgets.Layout(width='180px'))\n",
    "show_declustering_w = widgets.Checkbox(value=False, description=\"Afficher d√©groupement\")\n",
    "\n",
    "spot_type_w = widgets.ToggleButtons(\n",
    "    options=[('Hotspot (fortes valeurs)', 'hotspot'), ('Coldspot (faibles valeurs)', 'coldspot')],\n",
    "    description='Zone sp√©ciale:',\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='280px')\n",
    ")\n",
    "\n",
    "distribution_w = widgets.Dropdown(\n",
    "    options=[('Lognormal', 'lognormal'), ('Normal', 'normal')],\n",
    "    value='lognormal',\n",
    "    description='Distribution:',\n",
    "    layout=widgets.Layout(width='180px')\n",
    ")\n",
    "\n",
    "# Graine dynamique\n",
    "current_seed = {'val': _seed}\n",
    "\n",
    "run_button = widgets.Button(description=\"Tracer\", button_style='primary')\n",
    "random_seed_button = widgets.Button(description=\"Tracer avec nouvelle graine\", button_style='warning')\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_run_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        interactive_sampling_fixed_spot(\n",
    "            n=_n,\n",
    "            range_=range_w.value,\n",
    "            mean=mean_w.value,\n",
    "            var=sigma_w.value,\n",
    "            n_samples_all=n_samples_all_w.value,\n",
    "            n_samples_spot=n_samples_spot_w.value,\n",
    "            spot_size=_spot_size,\n",
    "            declust_cells=declust_cells_w.value,\n",
    "            show_declustering=show_declustering_w.value,\n",
    "            seed=current_seed['val'],\n",
    "            spot_type=spot_type_w.value,\n",
    "            distribution=distribution_w.value\n",
    "        )\n",
    "\n",
    "def on_random_seed_clicked(b):\n",
    "    current_seed['val'] = np.random.randint(0, 100000)\n",
    "    on_run_clicked(b)\n",
    "\n",
    "run_button.on_click(on_run_clicked)\n",
    "random_seed_button.on_click(on_random_seed_clicked)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([range_w, sigma_w, mean_w]),\n",
    "    widgets.HBox([n_samples_all_w, n_samples_spot_w, declust_cells_w]),\n",
    "    widgets.HBox([distribution_w]),\n",
    "    widgets.HBox([show_declustering_w, spot_type_w]),\n",
    "    widgets.HBox([run_button, random_seed_button]),\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af927470-1e2e-4ea1-8f17-2d2628b94bcc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
